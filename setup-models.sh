#!/bin/bash

echo "ğŸš€ Setting up TextLens AI Models..."
echo "This will download lightweight models to avoid system lag"
echo ""

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama is not installed. Please install Ollama first:"
    echo "   Visit: https://ollama.ai"
    echo "   Or run: curl -fsSL https://ollama.ai/install.sh | sh"
    exit 1
fi

echo "âœ… Ollama found, downloading lightweight models..."
echo ""

# Download lightweight models
echo "ğŸ“¥ Downloading TinyLlama (1.1B) - Fastest..."
ollama pull tinyllama

echo "ğŸ“¥ Downloading Phi-3 Mini (3.8B) - Balanced..."
ollama pull phi3

echo "ğŸ“¥ Downloading Gemma 2B (2B) - Google's model..."
ollama pull gemma2:2b

echo "ğŸ“¥ Downloading Llama 3.2 1B (1B) - Meta's smallest..."
ollama pull llama3.2:1b

echo ""
echo "ğŸ‰ All lightweight models downloaded!"
echo ""
echo "ğŸ“‹ Available models:"
echo "   â€¢ TinyLlama (1.1B) - âš¡âš¡âš¡ Fastest"
echo "   â€¢ Phi-3 Mini (3.8B) - âš¡âš¡ Balanced (Recommended)"
echo "   â€¢ Gemma 2B (2B) - âš¡âš¡âš¡ Google"
echo "   â€¢ Llama 3.2 1B (1B) - âš¡âš¡âš¡ Meta"
echo ""
echo "ğŸš€ To start Ollama: ollama serve"
echo "ğŸŒ Then visit: http://localhost:3000"
echo ""
echo "ğŸ’¡ Tip: Use Phi-3 Mini for the best balance of speed and quality!"
